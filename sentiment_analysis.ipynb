{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEK9W8iiQg0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc2028a7-4ff1-4352-d821-07e69dafba6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive/')\n",
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk \n",
        "!pip3 install konlpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive/\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [65.5 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [11.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:14 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [594 kB]\n",
            "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [33.0 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [727 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,672 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [902 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,250 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [3,930 B]\n",
            "Get:23 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [802 kB]\n",
            "Fetched 6,355 kB in 6s (1,046 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "g++ set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n",
            "  openjdk-8-jre-headless x11-utils\n",
            "Suggested packages:\n",
            "  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n",
            "  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jre x11-utils\n",
            "The following packages will be upgraded:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "2 upgraded, 13 newly installed, 0 to remove and 55 not upgraded.\n",
            "Need to get 42.8 MB of archives.\n",
            "After this operation, 20.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u222-b10-1ubuntu1~18.04.1 [8,267 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u222-b10-1ubuntu1~18.04.1 [27.4 MB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u222-b10-1ubuntu1~18.04.1 [69.3 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u222-b10-1ubuntu1~18.04.1 [1,756 kB]\n",
            "Fetched 42.8 MB in 33s (1,286 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 131331 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java.\n",
            "Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n",
            "Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n",
            "Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n",
            "Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Preparing to unpack .../11-openjdk-8-jdk-headless_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) over (8u212-b03-0ubuntu1.18.04.1) ...\n",
            "Preparing to unpack .../12-openjdk-8-jre-headless_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) over (8u212-b03-0ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jre:amd64.\n",
            "Preparing to unpack .../13-openjdk-8-jre_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Selecting previously unselected package openjdk-8-jdk:amd64.\n",
            "Preparing to unpack .../14-openjdk-8-jdk_8u222-b10-1ubuntu1~18.04.1_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n",
            "Setting up openjdk-8-jre:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n",
            "Setting up openjdk-8-jdk:amd64 (8u222-b10-1ubuntu1~18.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/3d/4e983cd98d87b50b2ab0387d73fa946f745aa8164e8888a714d5129f9765/konlpy-0.5.1-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 2.8MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.5.7 (from konlpy)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/09/e19ce27d41d4f66d73ac5b6c6a188c51b506f56c7bfbe6c1491db2d15995/JPype1-0.7.0-cp36-cp36m-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 28.6MB/s \n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-0.7.0 konlpy-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdLF_oyMTego",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "33263b15-c6ae-42bd-92b9-8ae6c4300e80"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "okt = Okt()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/jpype/_core.py:210: UserWarning: \n",
            "-------------------------------------------------------------------------------\n",
            "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
            "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
            "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
            "this session. If you are a user of an application that reported this warning,\n",
            "please file a ticket with the developer.\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMbsNc8tQjoI",
        "colab_type": "code",
        "outputId": "867bde3c-29a7-4fb9-b564-5ebc092858bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "!ls \"/drive/My Drive\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'CNN_실습_(문제).ipynb'\n",
            "'Colab Notebooks'\n",
            " data_deep.pkl\n",
            " data_ml.pkl\n",
            "'아르바이트 시간과 학점의 연관성 조.gform'\n",
            "'장학생 신청서 및 개인정보 수집이용 동의서 동의서.hwp'\n",
            "'시각화 코드 절차.ipynb'\n",
            "'Ques)Training_Neural_Network_.ipynb'\n",
            " sentiment_analysis.ipynb\n",
            "'submission.csv의 사본'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f-FCFqA5i8z",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/rudvlf0413/skt-exercise/blob/master/sentiment_analysis/preprocessing.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmhu2FHr6i4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrC9c3GgSGKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/drive/My Drive/data_deep.pkl', 'rb') as f:\n",
        "    index2voca = pickle.load(f)\n",
        "    voca2index = pickle.load(f)\n",
        "    train_X = pickle.load(f)\n",
        "    train_y = pickle.load(f)\n",
        "    test_X = pickle.load(f)\n",
        "    test_y = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Q7AzzE7leE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0fdbdbf1-6e4d-4d4e-aa16-0adf40837faf"
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251880, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moUI856pSkQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X, train_y = torch.LongTensor(train_X), torch.FloatTensor(train_y)\n",
        "test_X, test_y = torch.LongTensor(test_X), torch.FloatTensor(test_y)\n",
        "\n",
        "train_y, test_y = train_y.view(-1, 1), test_y.view(-1, 1)\n",
        "\n",
        "train_dataset = TensorDataset(train_X, train_y)\n",
        "test_dataset = TensorDataset(test_X, test_y)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRsjYD699rgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNRegressor(nn.Module):\n",
        "    \n",
        "    def __init__(self, voca_num, embedding_dim, filter_lengths=[2,3,4], filter_num=20):\n",
        "        super(CNNRegressor, self).__init__()\n",
        "        \n",
        "        self.voca_num = voca_num\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.filter_lengths = filter_lengths\n",
        "        self.filter_num = filter_num\n",
        "        \n",
        "        self.embedding=nn.Embedding(self.voca_num,self.embedding_dim,padding_idx=0)\n",
        "        self.filters= nn.ModuleList( [nn.Conv1d(1,self.filter_num,(i,embedding_dim)) for i in filter_lengths] )\n",
        "        \n",
        "        self.linear1=nn.Linear(len(self.filter_lengths)*self.filter_num,10)\n",
        "        self.linear2 = nn.Linear(10, 1)\n",
        "        \n",
        "    def forward(self,words):\n",
        "        embs=self.embedding(words)\n",
        "        embs=embs.unsqueeze(1)\n",
        "        \n",
        "        out=[torch.relu(conv(embs)) for conv in self.filters]\n",
        "        out=[o.squeeze(3) for o in out] #squeeze를 통해서 마지막에 추가가 되어있는 1을 제거\n",
        "        out=[F.max_pool1d(feature,feature.size(2)) for feature in out]\n",
        "        out=torch.cat(out,dim=1)\n",
        "        out=out.squeeze(2)\n",
        "        \n",
        "        out=torch.relu(self.linear1(out))\n",
        "        out=self.linear2(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eucc21zB5WM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device=torch.device('cuda')\n",
        "regressor=CNNRegressor(len(index2voca),128)\n",
        "regressor=regressor.to(device)\n",
        "\n",
        "mse_loss=nn.MSELoss()\n",
        "\n",
        "optimizer=torch.optim.Adam(regressor.parameters(),lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNYmwNkpIPLU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee1567c4-849f-4666-8b70-f8f47c01d901"
      },
      "source": [
        "epochs=5\n",
        "\n",
        "regressor.train()\n",
        "for e in range(epochs):\n",
        "    for i, (batch_X, batch_y) in enumerate(train_loader):\n",
        "        batch_X, batch_y =  batch_X.to(device), batch_y.to(device)\n",
        "        \n",
        "        predict=regressor(batch_X)\n",
        "        \n",
        "        loss=mse_loss(predict,batch_y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            loss=loss.item()\n",
        "            print(f\"{e}epochs, {i}iters-{loss}\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0epochs, 0iters-0.262140691280365\n",
            "0epochs, 100iters-0.0741741731762886\n",
            "0epochs, 200iters-0.07131094485521317\n",
            "0epochs, 300iters-0.045048102736473083\n",
            "0epochs, 400iters-0.05284129083156586\n",
            "0epochs, 500iters-0.06375740468502045\n",
            "0epochs, 600iters-0.06090252473950386\n",
            "0epochs, 700iters-0.06008525192737579\n",
            "0epochs, 800iters-0.05268924683332443\n",
            "0epochs, 900iters-0.049431148916482925\n",
            "0epochs, 1000iters-0.051765553653240204\n",
            "0epochs, 1100iters-0.052678704261779785\n",
            "0epochs, 1200iters-0.05286268889904022\n",
            "0epochs, 1300iters-0.05529302358627319\n",
            "0epochs, 1400iters-0.054035484790802\n",
            "0epochs, 1500iters-0.04556132107973099\n",
            "0epochs, 1600iters-0.05497920513153076\n",
            "0epochs, 1700iters-0.042695675045251846\n",
            "0epochs, 1800iters-0.06429576873779297\n",
            "0epochs, 1900iters-0.04851677268743515\n",
            "1epochs, 0iters-0.04458268731832504\n",
            "1epochs, 100iters-0.04107225686311722\n",
            "1epochs, 200iters-0.04824111983180046\n",
            "1epochs, 300iters-0.03224591910839081\n",
            "1epochs, 400iters-0.04384275898337364\n",
            "1epochs, 500iters-0.04912794381380081\n",
            "1epochs, 600iters-0.05071420967578888\n",
            "1epochs, 700iters-0.04529934003949165\n",
            "1epochs, 800iters-0.039710886776447296\n",
            "1epochs, 900iters-0.03971250727772713\n",
            "1epochs, 1000iters-0.0437922328710556\n",
            "1epochs, 1100iters-0.040333185344934464\n",
            "1epochs, 1200iters-0.040412917733192444\n",
            "1epochs, 1300iters-0.04315199330449104\n",
            "1epochs, 1400iters-0.039697326719760895\n",
            "1epochs, 1500iters-0.04423832893371582\n",
            "1epochs, 1600iters-0.046989668160676956\n",
            "1epochs, 1700iters-0.03543467074632645\n",
            "1epochs, 1800iters-0.05382333695888519\n",
            "1epochs, 1900iters-0.041307467967271805\n",
            "2epochs, 0iters-0.034401342272758484\n",
            "2epochs, 100iters-0.0329989530146122\n",
            "2epochs, 200iters-0.03842941299080849\n",
            "2epochs, 300iters-0.027278829365968704\n",
            "2epochs, 400iters-0.03536950796842575\n",
            "2epochs, 500iters-0.037249110639095306\n",
            "2epochs, 600iters-0.04030707851052284\n",
            "2epochs, 700iters-0.043694086372852325\n",
            "2epochs, 800iters-0.03310907632112503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-e6a81cd56a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zERz4SCsSrqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#원본\n",
        "\n",
        "class CNNRegressor(nn.Module):\n",
        "    def __init__(self, voca_num, embedding_dim, filter_lengths, filter_num=20):\n",
        "        super(CNNRegressor, self).__init__()\n",
        "        \n",
        "        self.voca_num = voca_num\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.filter_lengths = filter_lengths\n",
        "        self.filter_num = filter_num\n",
        "        \n",
        "        self.embedding = nn.Embedding(self.voca_num, self.embedding_dim, padding_idx=0)\n",
        "        self.filters = nn.ModuleList([nn.Conv1d(1, self.filter_num, (l, self.embedding_dim)) for l in self.filter_lengths])\n",
        "        \n",
        "        self.linear1 = nn.Linear(self.filter_num*len(self.filter_lengths), 10)\n",
        "        self.linear2 = nn.Linear(10, 1)\n",
        "        \n",
        "    def forward(self, words):\n",
        "        embs = self.embedding(words)\n",
        "        embs = embs.unsqueeze(1)\n",
        "        features = [F.relu(conv(embs)) for conv in self.filters]\n",
        "        features = [f.squeeze(3) for f in features]\n",
        "        features = [F.max_pool1d(f, f.size(2)) for f in features]\n",
        "        output = torch.cat(features, dim=1)\n",
        "        output = output.squeeze(2)\n",
        "        output = torch.relu(self.linear1(output))\n",
        "        output = self.linear2(output)\n",
        "        return output\n",
        "    \n",
        "\n",
        "class RNNRegressor(nn.Module):\n",
        "    def __init__(self, voca_num, embedding_dim, hidden_dim, num_layer=2, bidirectional=True):\n",
        "        super(RNNRegressor, self).__init__()\n",
        "        self.voca_num = voca_num\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layer = num_layer\n",
        "        self.bidirectional = bidirectional\n",
        "        \n",
        "        self.embedding = nn.Embedding(voca_num, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=self.num_layer,\n",
        "                          bidirectional=self.bidirectional, batch_first=True)\n",
        "        self.linear1 = nn.Linear(hidden_dim*(self.bidirectional + 1), 10)\n",
        "        self.linear2 = nn.Linear(10, 1)\n",
        "        \n",
        "    def forward(self, words):\n",
        "        embs = self.embedding(words)\n",
        "        output, h_n = self.gru(embs)\n",
        "        output = output[:, -1, :]\n",
        "        output = torch.relu(self.linear1(output))\n",
        "        output = self.linear2(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXPNXECbX0oH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "# reg = CNNRegressor(len(index2voca), 128, [2, 3, 4])\n",
        "reg = RNNRegressor(len(index2voca), 256, 256, num_layer=2, bidirectional=True)\n",
        "reg = reg.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optim = torch.optim.Adam(reg.parameters(), lr=1e-3, weight_decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtnrjUz9YSC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "reg.train()\n",
        "for e in range(epochs):\n",
        "    for i, (batch_X, batch_y) in enumerate(train_loader):\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        \n",
        "        predict = reg(batch_X)\n",
        "        \n",
        "        loss = criterion(predict, batch_y)\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(reg.parameters(), 0.5)\n",
        "        optim.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            loss = loss.item()\n",
        "            print(f\"{e}epochs, {i}iters - {loss}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BXZ9CFZe34w",
        "colab_type": "code",
        "outputId": "e435b52f-f56a-409f-a35b-d474c209d65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_loss = []\n",
        "test_num = 0\n",
        "l1_loss = nn.L1Loss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    reg.eval()\n",
        "    for i, (batch_X, batch_y) in enumerate(test_loader):\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "        predict = reg(batch_X)\n",
        "        predict = torch.clamp(predict, min=0, max=1)\n",
        "        \n",
        "        loss = l1_loss(predict, batch_y)\n",
        "        loss = loss.item()\n",
        "        batch_size = batch_X.size(0)\n",
        "        test_num += batch_size\n",
        "        total_loss.append(loss*batch_size)\n",
        "        \n",
        "total_loss = np.sum(total_loss)/test_num\n",
        "print(total_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2779954965793842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBRtfysOJWkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLZGVbMYJWiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from konlpy.tag import Twitter\n",
        "from glob import glob\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "from random import shuffle\n",
        "from pprint import pprint\n",
        "from scipy.sparse import dok_matrix\n",
        "import numpy as np\n",
        "# import ujson as json\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCs6o_e2K1IY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m1NcENLJWfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"이 영화 정말 재밌다\"\n",
        "okt=Okt()\n",
        "parsed = okt.morphs(sentence)\n",
        "\n",
        "vector=np.zeros((1,100))\n",
        "\n",
        "for i, word in enumerate(parsed):\n",
        "    vector[0,i] = voca2index[word]\n",
        "    \n",
        "vector = torch.from_numpy(vector).long().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WymPDccVJWcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "20c62907-70a4-47c6-e9f0-23731ff00aaa"
      },
      "source": [
        "vector"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2,   3,  47, 325,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqTb5V9tLD_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "39f0baef-28c8-43d5-a440-160cc18f69de"
      },
      "source": [
        "sentence = \"이 영화 정말 재미없다\" #해당되는 재미없다 단어가 없는 상태임\n",
        "okt=Okt()\n",
        "parsed = okt.morphs(sentence)\n",
        "\n",
        "vector=np.zeros((1,100))\n",
        "\n",
        "for i, word in enumerate(parsed):\n",
        "    vector[0,i] = voca2index[word]\n",
        "    \n",
        "vector = torch.from_numpy(vector).long().to(device)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-ca866881483a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mvector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoca2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '재미없다'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqYtR11CLD9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"이 영화 정말 재미없다\" #해당되는 재미없다 단어가 없는 상태임\n",
        "okt=Okt()\n",
        "parsed = okt.morphs(sentence)\n",
        "\n",
        "vector=np.zeros((1,100))\n",
        "\n",
        "for i, word in enumerate(parsed):\n",
        "    if word in voca2index:\n",
        "        vector[0,i] += voca2index[word]\n",
        "    else:\n",
        "        vector[0,i] += voca2index['<UNK>']\n",
        "    \n",
        "vector = torch.from_numpy(vector).long().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dzru-fILD7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "806fa710-ec56-47d9-f46b-01818010f558"
      },
      "source": [
        "vector"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,     3,    47, 19999,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2ph30Z_LDw9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c17e62b-584b-4668-d6a2-a537f7072206"
      },
      "source": [
        "regressor(vector).item()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3064884543418884"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlSaTthULr2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"이 영화 정말 지루하다\" \n",
        "okt=Okt()\n",
        "parsed = okt.morphs(sentence)\n",
        "\n",
        "vector=np.zeros((1,100))\n",
        "\n",
        "for i, word in enumerate(parsed):\n",
        "    if word in voca2index:\n",
        "        vector[0,i] += voca2index[word]\n",
        "    else:\n",
        "        vector[0,i] += voca2index['<UNK>']\n",
        "    \n",
        "vector = torch.from_numpy(vector).long().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np08a9cdLr05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f695f86-38ec-4ddb-b5e2-210d5a1f6ddb"
      },
      "source": [
        "regressor(vector).item()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2387334555387497"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuFlu8eaLryK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNRegressor(nn.Module):\n",
        "    def __init__(self,voca_num,embedding_dim, hidden_dim):\n",
        "        super(RNNRegressor,self).__init__()\n",
        "        \n",
        "        self.voca_num = voca_num\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(voca_num, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(self.embedding_dim, self.hidden_dim, batch_first=True, bidirectional=True,num_layers=2)\n",
        "        self.linear1 = nn.Linear(2*self.hidden_dim, 10)\n",
        "        self.linear2 = nn.Linear(10, 1)\n",
        "        \n",
        "        \n",
        "    def forward(self,word_indices):\n",
        "        embs=self.embedding(word_indices)\n",
        "        \n",
        "        output, (h_n, c_n) = self.lstm(embs)\n",
        "        output= output[:,-1,:]\n",
        "        \n",
        "        output=torch.relu(self.linear1(output))\n",
        "        output=self.linear2(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir5gFLqPLrvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "# reg = CNNRegressor(len(index2voca), 128, [2, 3, 4])\n",
        "reg = RNNRegressor(len(index2voca), 128, 128)\n",
        "reg = reg.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optim = torch.optim.Adam(reg.parameters(), lr=1e-3, weight_decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkbschleLrtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "252f6e5c-0dc4-43ea-c38c-f733fcf5e56a"
      },
      "source": [
        "epochs=5\n",
        "\n",
        "regressor.train()\n",
        "for e in range(epochs):\n",
        "    for i, (batch_X, batch_y) in enumerate(train_loader):\n",
        "        batch_X, batch_y =  batch_X.to(device), batch_y.to(device)\n",
        "        \n",
        "        predict=regressor(batch_X)\n",
        "        \n",
        "        loss=mse_loss(predict,batch_y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            loss=loss.item()\n",
        "            print(f\"{e}epochs, {i}iters-{loss}\")"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0epochs, 0iters-0.022421497851610184\n",
            "0epochs, 100iters-0.041388075798749924\n",
            "0epochs, 200iters-0.027331089600920677\n",
            "0epochs, 300iters-0.05903324484825134\n",
            "0epochs, 400iters-0.023417159914970398\n",
            "0epochs, 500iters-0.041844312101602554\n",
            "0epochs, 600iters-0.0280019361525774\n",
            "0epochs, 700iters-0.031860027462244034\n",
            "0epochs, 800iters-0.04632902145385742\n",
            "0epochs, 900iters-0.023634890094399452\n",
            "0epochs, 1000iters-0.026830220595002174\n",
            "0epochs, 1100iters-0.030313536524772644\n",
            "0epochs, 1200iters-0.033939510583877563\n",
            "0epochs, 1300iters-0.041720107197761536\n",
            "0epochs, 1400iters-0.0329010970890522\n",
            "0epochs, 1500iters-0.036199554800987244\n",
            "0epochs, 1600iters-0.025153741240501404\n",
            "0epochs, 1700iters-0.023320890963077545\n",
            "0epochs, 1800iters-0.04114970564842224\n",
            "0epochs, 1900iters-0.03554493561387062\n",
            "1epochs, 0iters-0.026884762570261955\n",
            "1epochs, 100iters-0.018672293052077293\n",
            "1epochs, 200iters-0.03155139088630676\n",
            "1epochs, 300iters-0.022098306566476822\n",
            "1epochs, 400iters-0.02218051068484783\n",
            "1epochs, 500iters-0.04494589567184448\n",
            "1epochs, 600iters-0.028565799817442894\n",
            "1epochs, 700iters-0.027714192867279053\n",
            "1epochs, 800iters-0.03205797076225281\n",
            "1epochs, 900iters-0.024724990129470825\n",
            "1epochs, 1000iters-0.026822054758667946\n",
            "1epochs, 1100iters-0.03046397864818573\n",
            "1epochs, 1200iters-0.03070930577814579\n",
            "1epochs, 1300iters-0.027936261147260666\n",
            "1epochs, 1400iters-0.040791768580675125\n",
            "1epochs, 1500iters-0.026871897280216217\n",
            "1epochs, 1600iters-0.023373182862997055\n",
            "1epochs, 1700iters-0.023326534777879715\n",
            "1epochs, 1800iters-0.03683488070964813\n",
            "1epochs, 1900iters-0.027144066989421844\n",
            "2epochs, 0iters-0.02152927592396736\n",
            "2epochs, 100iters-0.028049655258655548\n",
            "2epochs, 200iters-0.025239769369363785\n",
            "2epochs, 300iters-0.03707412630319595\n",
            "2epochs, 400iters-0.025302957743406296\n",
            "2epochs, 500iters-0.026282187551259995\n",
            "2epochs, 600iters-0.04812682420015335\n",
            "2epochs, 700iters-0.06928408145904541\n",
            "2epochs, 800iters-0.028672099113464355\n",
            "2epochs, 900iters-0.025409813970327377\n",
            "2epochs, 1000iters-0.04222538694739342\n",
            "2epochs, 1100iters-0.02635655365884304\n",
            "2epochs, 1200iters-0.03165094554424286\n",
            "2epochs, 1300iters-0.03470023348927498\n",
            "2epochs, 1400iters-0.02014373429119587\n",
            "2epochs, 1500iters-0.0469813197851181\n",
            "2epochs, 1600iters-0.025664666667580605\n",
            "2epochs, 1700iters-0.04426855221390724\n",
            "2epochs, 1800iters-0.035168904811143875\n",
            "2epochs, 1900iters-0.024866165593266487\n",
            "3epochs, 0iters-0.04141410440206528\n",
            "3epochs, 100iters-0.04987851530313492\n",
            "3epochs, 200iters-0.022757109254598618\n",
            "3epochs, 300iters-0.0292150117456913\n",
            "3epochs, 400iters-0.02646706998348236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-e6a81cd56a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2256\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a7cI3JUPc33",
        "colab_type": "text"
      },
      "source": [
        "rnn 은 dropout을 잘 사용 안함. 정보 손실이 너무 큼"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkijhQENu6U4",
        "colab_type": "code",
        "outputId": "dafb932e-9915-43a8-d784-e7b69d9b3c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#원본\n",
        "\n",
        "ext = \"이 영화 정말 감동적이다\"\n",
        "parsed = okt.morphs(text)\n",
        "\n",
        "vector = np.zeros((1, train_X.shape[1]))\n",
        "for i, w in enumerate(parsed):\n",
        "    if w in voca2index:\n",
        "        vector[0, i] += voca2index[w]\n",
        "    \n",
        "vector = torch.from_numpy(vector).long().to(device)\n",
        "predict = torch.sigmoid(reg(vector)).item()\n",
        "print(predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6258990168571472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhaWz0W3gyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}